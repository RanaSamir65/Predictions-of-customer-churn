#Reading the Cluster3 set
Cluster3= read.csv("Cluster3.csv")
Cluster3$Cluster = NULL
str(Cluster3)
summary(Cluster3)
table(Cluster3$Education_Level)
table(Cluster3$Income_Category)

#Preparing the Cluster3set
Cluster3$Attrition_Flag = ifelse(Cluster3$Attrition_Flag == "Existing Customer", 0, 1)
Cluster3$CLIENTNUM = NULL
Cluster3$Gender = ifelse(Cluster3$Gender == "F", 1, 0)
Cluster3$Education_Level = ifelse(Cluster3$Education_Level == "Unknown", 1, ifelse(Cluster3$Education_Level == "Uneducated", 2, ifelse(Cluster3$Education_Level == "High School", 3, ifelse(Cluster3$Education_Level == "College", 4, ifelse(Cluster3$Education_Level == "Graduate", 5, ifelse(Cluster3$Education_Level == "Post-Graduate",6,ifelse(Cluster3$Education_Level == "Doctorate",7,8)))))))
Cluster3$Income_Category = ifelse(Cluster3$Income_Category == "Unknown", 1, ifelse(Cluster3$Income_Category == "Less than $40K", 2, ifelse(Cluster3$Income_Category == "$40K - $60K", 3, ifelse(Cluster3$Income_Category == "$60K - $80K", 4, ifelse(Cluster3$Income_Category == "$80K - $120K", 5, ifelse(Cluster3$Income_Category == "$120K +",6,7))))))
Marital_Status = unique(Cluster3$Marital_Status)
Marital_Status
for (a in Marital_Status){
  assign(paste(a), ifelse(Cluster3$Marital_Status == a,1,0))
}
Cluster3$Married = Married
Cluster3$Single = Single
Cluster3$Marital_Status_Unknown = Unknown
Cluster3$Divorced = Divorced
Cluster3$Marital_Status = NULL
Card_Category = unique(Cluster3$Card_Category)
Card_Category
for (c in Card_Category){
  assign(paste(c), ifelse(Cluster3$Card_Category == c,1,0))
}
Cluster3$Gold = Gold
Cluster3$Silver = Silver
Cluster3$Platinum = Platinum
Cluster3$Card_Category = NULL
#splitting the Cluster3 set into training and testing set
library(caTools)
set.seed(144)
spl = sample.split(Cluster3$Attrition_Flag, SplitRatio=0.7)
TrainCluster3 = subset(Cluster3, spl==TRUE)
TestCluster3 = subset(Cluster3, spl==FALSE)

#Baseline accuracy

table(TestCluster3$Attrition_Flag)
acc = 163 / 192
acc
#0.8489583

#Using Logistic Regression model
LogReg = glm(Attrition_Flag~. ,  data = TrainCluster3, family = binomial)
summary(LogReg)

#Remove insignificant variables
Regression_Data = TrainCluster3
Regression_Data$Marital_Status_Unknown = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Divorced = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Married = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Customer_Age = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Gender = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Income_Category = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Total_Amt_Chng_Q4_Q1 = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Gold = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Platinum = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Education_Level = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Months_on_book = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Single = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Credit_Limit = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Avg_Open_To_Buy = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Avg_Utilization_Ratio = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)
Regression_Data$Dependent_count = NULL
LogReg = glm(Attrition_Flag~. ,  data = Regression_Data, family = binomial)
summary(LogReg)

#prediction using logistic regression model
PredLogReg = predict(LogReg, newdata= TestCluster3, type = "response")

library(ROCR)
ROCRpred = prediction(PredLogReg, TestCluster3$Attrition_Flag)
ROCRperf = performance(ROCRpred,"tpr","fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1),text.adj=c(-0.5,0.5))

#Try Threshold 0.10 
table(TestCluster3$Attrition_Flag, PredLogReg>0.10)
AccuracyLog = ( 27 + 125) / 192
AccuracyLog
#0.7916667

#Try Threshold 0.20 
table(TestCluster3$Attrition_Flag, PredLogReg>0.20)
AccuracyLog = ( 19 + 147) / 192
AccuracyLog
#0.8645833
sensitivity = 19/29
sensitivity
specificity=147/163
specificity



#Using CART model
library(rpart)
library(rpart.plot)

#determine the cp to be used
library(caret)
set.seed(2)
Cpcontrol = trainControl( method = "cv", number = 10 )
Grid = data.frame(.cp = seq(0,0.092,0.001))
cartCV = train(Attrition_Flag~. , data = TrainCluster3, method = "rpart", trControl = Cpcontrol, tuneGrid = Grid )
cartCV
plot(cartCV)
#best cp is 0.006

CART = rpart(Attrition_Flag~., data = TrainCluster3, method = "class", cp = 0.006)
prp(CART)
PredCART = predict(CART, newdata= TestCluster3)
PredCART
pred.prob = PredCART[,2]

ROCRpred = prediction(pred.prob, TestCluster3$Attrition_Flag)
ROCRperf = performance(ROCRpred,"tpr","fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1),text.adj=c(-0.5,0.5))

#Try Threshold 0.1 
table(TestCluster3$Attrition_Flag, pred.prob > 0.1)
AccuracyCART = (19 + 156) / 192
AccuracyCART
# 0.9114583

#Try Threshold 0.2 
table(TestCluster3$Attrition_Flag, pred.prob > 0.2)
AccuracyCART = (19 + 156) / 192
AccuracyCART
#0.9114583

#Try Threshold 0.3 (Best)
table(TestCluster3$Attrition_Flag, pred.prob > 0.3)
AccuracyCART = (19 + 156) / 192
AccuracyCART
#0.9114583
sensitivity = 19/29
sensitivity
specificity=156/163
specificity

table(TestCluster3$Attrition_Flag, pred.prob > 0.4)
AccuracyCART = (15 + 158) / 192
AccuracyCART
#0.9010417

#Use random forest model
library(randomForest)
set.seed(1)
RanFor = randomForest(Attrition_Flag ~ . , data = TrainCluster3, importance= TRUE)
RanFor
# error = 0.0617413
plot(RanFor, type = "simple")

varImpPlot(RanFor, sort=TRUE, n.var=15)
PredRanFor = predict(RanFor, newdata=TestCluster3)

ROCRpred = prediction(PredRanFor, TestCluster3$Attrition_Flag)
ROCRperf = performance(ROCRpred,"tpr","fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1),text.adj=c(-0.5,0.5))

#Try Threshold 0.2
table(TestCluster3$Attrition_Flag, PredRanFor > 0.2)
Accuracy = (26 + 141) / 192
Accuracy
#0.8697917

#Try Threshold 0.3 (Best)
table(TestCluster3$Attrition_Flag, PredRanFor > 0.3)
Accuracy = (24 + 154) / 192
Accuracy
# 0.9270833
sensitivity = 24/29
sensitivity
specificity=154/163
specificity

#Try Threshold 0.4 
table(TestCluster3$Attrition_Flag, PredRanFor > 0.4)
Accuracy = (18+ 157) / 192
Accuracy
#0.9114583
